{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\nur\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\nur\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\nur\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\nur\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\nur\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\nur\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\nur\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\nur\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\nur\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\nur\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\nur\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\nur\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model,Input\n",
    "\n",
    "from keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense,concatenate\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_ops(object):\n",
    "    def __init__(self, path,file_name,sep,use_cols):\n",
    "        self.path = path #path of the file\n",
    "        self.file_name = file_name #the data file name\n",
    "        self.sep = sep # delimiter if any\n",
    "        self.columns = use_cols  # which columns to use in this dataset\n",
    "\n",
    "    def read_data(self):\n",
    "        self.data = pd.read_csv(self.path,sep = self.sep, usecols = self.columns) # read the dataset from the given path\n",
    "        self.data.columns = self.columns #filter out unwanted columns\n",
    "\n",
    "    #This method scales the data into 0,1 scale\n",
    "    def scale_data(self): \n",
    "        self.scaler = MinMaxScaler() # minmaxscaler object to scale our data\n",
    "        target_val = self.data[self.columns[2]].values #our target value is the last column\n",
    "        target_val = target_val.reshape(-1,1) # Reshape the target value to [n,1] to avoid shape error\n",
    "        self.scaler.fit(target_val) # fit the target values to scaler object\n",
    "        self.data[self.columns[2]] = self.scaler.transform(target_val) # replace unscaled target value with the scaled one.\n",
    "\n",
    "    def create_train_matrix(self): # create training matrix for the network\n",
    "        grouped_data  = self.data.groupby([self.columns[0],self.columns[1]])[self.columns[2]].sum().unstack().fillna(0)\n",
    "        self.train_matrix = grouped_data.values \n",
    "\n",
    "    def generator_IE(self):\n",
    "        #print(np.array(self.train_matrix).shape)\n",
    "        for row in range(len(self.train_matrix)):\n",
    "            item = (np.array(self.train_matrix[row]))\n",
    "            print(\"output \" , (item,item))\n",
    "            yield (item,item)\n",
    "    \n",
    "    def get_data(self):\n",
    "        self.read_data()\n",
    "        self.scale_data()\n",
    "        self.create_train_matrix()\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Models(object):\n",
    "\n",
    "    def __init__(self, gen):\n",
    "        self.generator = gen\n",
    "        self.item_size = 4\n",
    "       \n",
    "    def item_Encoder(self): \n",
    "        input = Input(shape=(1,))\n",
    "        code = Dense(self.item_size*2, activation=\"relu\", name='IE_hidden1')(input)\n",
    "        code = Dense(int(self.item_size*2), activation=\"relu\",name='IE_hidden2')(code)\n",
    "        self.item_input = input\n",
    "        return code\n",
    "\n",
    "    def item_Decoder(self,code):    \n",
    "        output = Dense(int(self.item_size*2), activation=\"relu\",name='ID_hidden3')(code)\n",
    "        output=  Dense(1, activation=\"relu\",name='ID_hidden4')(output)\n",
    "        return output\n",
    "\n",
    "    def model_train_IE(self):\n",
    "       \n",
    "        self.item_code = self.item_Encoder()\n",
    "        item_dec = self.item_Decoder(self.item_code)\n",
    "        self.imodel = Model(inputs=self.item_input, outputs=item_dec)\n",
    "        \n",
    "        self.imodel.compile(loss='mse',optimizer='sgd',metrics=[\"mse\"])\n",
    "        self.imodel.fit(x=gen,epochs=5,steps_per_epoch=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output  (array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.28825623, 0.        ]), array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.28825623, 0.        ]))\n",
      "output  (array([0., 0., 0., 0., 0., 1., 0., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0.]))\n",
      "output  (array([0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0.]))\n",
      "output  (array([0.        , 0.        , 0.        , 0.        , 0.28825623,\n",
      "       0.        , 0.        , 0.        ]), array([0.        , 0.        , 0.        , 0.        , 0.28825623,\n",
      "       0.        , 0.        , 0.        ]))\n",
      "output  (array([0., 0., 0., 0., 0., 1., 0., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0.]))\n",
      "output  (array([0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0.]))\n",
      "output  (array([0.        , 0.        , 0.        , 0.28825623, 0.        ,\n",
      "       0.        , 0.        , 0.        ]), array([0.        , 0.        , 0.        , 0.28825623, 0.        ,\n",
      "       0.        , 0.        , 0.        ]))\n",
      "output  (array([0.28825623, 0.28825623, 0.28825623, 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        ]), array([0.28825623, 0.28825623, 0.28825623, 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        ]))\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0050 - mse: 0.0050\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0604 - mse: 0.0604\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.4522e-05 - mse: 5.4522e-05\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0047 - mse: 0.0047\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0587 - mse: 0.0587\n"
     ]
    }
   ],
   "source": [
    "path = \"deneme.csv\"\n",
    "fname = \"deneme.csv\"\n",
    "dobject = data_ops(path,fname,\";\",[\"STORE_ID\",\"ITEM_CODE\",\"SALES_QUANTITY\"])\n",
    "dobject.get_data()\n",
    "gen = dobject.generator_IE()\n",
    "\n",
    "ae = Models(gen)\n",
    "ae.model_train_IE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "IE_hidden1 (Dense)           (None, 8)                 16        \n",
      "_________________________________________________________________\n",
      "IE_hidden2 (Dense)           (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "ID_hidden3 (Dense)           (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "ID_hidden4 (Dense)           (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 169\n",
      "Trainable params: 169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(ae.imodel.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output  (array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.28825623, 0.        ]), array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.28825623, 0.        ]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(next(dobject.generator_IE())).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
